
from typing import List

import torch
import torchvision

from PIL import Image
from tqdm import tqdm

from dataset import Glint360KSubset_Base


class Glint360KSubset_Noise(Glint360KSubset_Base):

    def __init__(
            self, 
            trans,
            loc
            ):
        
        super().__init__(trans, loc)

    def __getitem__(self, x):

        image_loc = self.items[x]
        image = self.trans(Image.open(image_loc).convert("RGB"))

        return image_loc, image
    
    def __len__(self):
        return len(self.items)


def generate_noise_scores(
        fr_model: torch.nn.Module, 
        trans: torchvision.transforms.Compose, 
        loc: str, 
        batch_size: int, 
        sim_func: torch.nn.Module, 
        alphas: List[float]) -> dict:
    """Generates quality scores using noise as the perturbation of choice.

    Args:
        fr_model (torch.nn.Module): Face Recognition used to generate the pseudo quality labels.
        trans (torchvision.transforms.v2.Compose): Function that prepares images for input to the FR model.
        loc (str): Location of the dataset used to generate the labels over.
        batch_size (int): Batch size.
        sim_func (torch.nn.Module): Similarity function used to compare the features of the original and perturbed images.
        alphas (List[float]): List of floats, determining the amount of noise to include in the perturbed image.

    Returns:
        dict: {"Image path": quality_score} values generated by the noise perturbation.
    """

    # Prepare FR model
    fr_model.cuda().eval()

    # Get occlusion specific dataset and construct dataloader
    dataset = Glint360KSubset_Noise(trans, loc)
    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size)

    noise_results = {}
    noise_masks = torch.randn((10, 3, 112, 112))
    # Generate results by comparing original to noisy images
    with torch.no_grad(), torch.autocast("cuda"):

        for (image_loc_batch, image_batch) in tqdm(dataloader, "Generating Noise Scores: "):
                
            base_emb = fr_model(image_batch.cuda()).detach()
            
            current_sims = torch.tensor([]).cuda()

            for alpha in alphas:

                for noise_mask in noise_masks:

                    noised_emb = fr_model( 
                        ((1. - alpha) * image_batch.clone() + alpha * noise_mask.unsqueeze(0).repeat(image_batch.size(0), 1, 1, 1)).cuda()
                        ).detach()

                    current_sims = torch.cat((
                        current_sims, sim_func(base_emb, noised_emb).unsqueeze(0)
                    ), dim=0)

            noise_results.update(dict(zip(image_loc_batch, torch.mean(current_sims, dim=0).detach().cpu().numpy().tolist())))

    return noise_results
